{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from nltk import word_tokenize, RegexpTokenizer, FreqDist\n",
    "import nltk.classify\n",
    "from nltk.classify import maxent\n",
    "import random\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "stpwords = stopwords.words('english')\n",
    "import re\n",
    "import pickle\n",
    "import sys\n",
    "from nltk import ngrams\n",
    "\n",
    "\n",
    "## extra output for debugging\n",
    "debug = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def first_pass(train_xml, test_xml, num_features=100):\n",
    "    train, Ytrain, test, Ytest = revs_labels(train_xml, test_xml)\n",
    "\n",
    "    all_words, all_bigrams, all_trigrams, feat_words, feat_bigrams, feat_trigrams = get_vocab(train, num_features)\n",
    "\n",
    "    x_feat_list = features(train, feat_words, feat_bigrams, feat_trigrams)\n",
    "    y_feat_list = features(test, feat_words, feat_bigrams, feat_trigrams)\n",
    "    test_zip = list(zip (y_feat_list, Ytest))\n",
    "    train_zip = list(zip (x_feat_list, Ytrain))\n",
    "\n",
    "    model, pred = run_model(train_zip, test_zip)\n",
    "    return model\n",
    "\n",
    "def second_pass(train_xml, test_xml, feat_words):\n",
    "    train, Ytrain, test, Ytest = revs_labels(train_xml, test_xml)\n",
    "\n",
    "    x_feat_list = features(train, feat_words, feat_bigrams, feat_trigrams)\n",
    "    y_feat_list = features(test, feat_words, feat_bigrams, feat_trigrams)\n",
    "    test_zip = list(zip (y_feat_list, Ytest))\n",
    "    train_zip = list(zip (x_feat_list, Ytrain))\n",
    "\n",
    "    model, pred = run_model(train_zip, test_zip)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 1800 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# if len(sys.argv) > 1:\n",
    "#     trainfile = sys.argv[1]\n",
    "# elif len(sys.argv) > 2:\n",
    "#     testfile = sys.argv[2]\n",
    "# else:\n",
    "trainfile = \"TrainingSet.xml\"\n",
    "\n",
    "\n",
    "tree = ET.parse(trainfile)\n",
    "root = tree.getroot()\n",
    "root = [rev for rev in root]\n",
    "random.shuffle(root, lambda: 0.424125125437)\n",
    "\n",
    "train_xml = root[:1800]\n",
    "test_xml = root[1800:]\n",
    "# train_xml = root[:20]\n",
    "# test_xml = root[1890:]\n",
    "if debug: print(len(root), len(train_xml), len(test_xml))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def revs_labels(train_xml, test_xml):\n",
    "    train  = [0] * len(train_xml)\n",
    "    Ytrain = [0] * len(train_xml)\n",
    "    train_ID = [0] * len(train_xml)\n",
    "    for i in range(len(train_xml)):\n",
    "        train[i] = train_xml[i].find(\"review_text\").text.lower()\n",
    "        y = float(train_xml[i].find(\"rating\").text)\n",
    "        if (y < 3):\n",
    "            Ytrain[i] = 'neg'\n",
    "        else:\n",
    "            Ytrain[i] = 'pos'\n",
    "        train_ID[i] = train_xml[i].find(\"unique_id\").text\n",
    "\n",
    "\n",
    "    # train[0].find(\"review_text\").text\n",
    "    test  = [0] * len(test_xml)\n",
    "    Ytest = [0] * len(test_xml)\n",
    "    test_ID  = [0] * len(test_xml)\n",
    "    for i in range(len(test_xml)):\n",
    "        test[i] = test_xml[i].find(\"review_text\").text.lower()\n",
    "        Ytest[i] = str(int(float(test_xml[i].find(\"rating\").text)))\n",
    "        y = float(test_xml[i].find(\"rating\").text)\n",
    "        if (y < 3):\n",
    "            Ytest[i] = 'neg'\n",
    "        else:\n",
    "            Ytest[i] = 'pos'\n",
    "        test_ID[i] = test_xml[i].find(\"unique_id\").text\n",
    "    return train, Ytrain, train_ID, test, Ytest, test_ID\n",
    "\n",
    "\n",
    "def get_vocab(train, num_words=500, num_bigrams=50, num_trigrams=10):\n",
    "    tokenizer = RegexpTokenizer(r'[a-z][a-z\\']*').tokenize\n",
    "    tokenized = [tokenizer(rev) for rev in train]\n",
    "\n",
    "    all_words = [x for rev in tokenized for x in rev]\n",
    "    all_words = [x for x in all_words if x not in stpwords]\n",
    "    all_bigrams = list(ngrams(all_words, 2))\n",
    "    all_trigrams = list(ngrams(all_words, 3))\n",
    "\n",
    "    word_fdist = FreqDist(all_words)\n",
    "    bigram_fdist = FreqDist(all_bigrams)\n",
    "    trigram_fdist = FreqDist(all_trigrams)\n",
    "\n",
    "    feat_words = word_fdist.most_common(num_words)\n",
    "    feat_bigrams = bigram_fdist.most_common(num_bigrams)\n",
    "    feat_trigrams = trigram_fdist.most_common(num_trigrams)\n",
    "\n",
    "    feat_words = [a for a,b in feat_words]\n",
    "    feat_bigrams = [a for a,b in feat_bigrams]\n",
    "    feat_trigrams = [a for a,b in feat_trigrams]\n",
    "\n",
    "\n",
    "    return all_words, all_bigrams, all_trigrams, feat_words, feat_bigrams, feat_trigrams\n",
    "#     return all_words, all_bigrams, feat_words, feat_bigrams\n",
    "\n",
    "\n",
    "\n",
    "def features (revs, words, bigrams, trigrams):\n",
    "    feat_list = []\n",
    "    tokenizer = RegexpTokenizer(r'[a-z][a-z\\']*').tokenize\n",
    "    for text in revs:\n",
    "        feat = {}\n",
    "        tokens = [x for x in tokenizer(text) if x not in stpwords]\n",
    "        text_bigrams = list(ngrams(tokens, 2))\n",
    "        text_trigrams = list(ngrams(tokens, 3))\n",
    "#         print(text_trigrams)\n",
    "        for bg in bigrams:\n",
    "            feat[bg] = int(bg in text_bigrams)\n",
    "        for tg in trigrams:\n",
    "            feat[tg] = int(tg in text_trigrams)\n",
    "        for word in words:\n",
    "            feat[word] = int(word in text)\n",
    "        feat_list.append(feat)\n",
    "\n",
    "    return feat_list\n",
    "\n",
    "def find_best_feats(model, num_features=100):\n",
    "    from contextlib import redirect_stdout\n",
    "    ## nltk's most informative features prints to std out\n",
    "    #  extract labels from output\n",
    "\n",
    "    with open('help.txt', 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            model.show_most_informative_features(300)\n",
    "    with open('help.txt', 'r') as f:\n",
    "        idk = re.findall(u'\\s[a-z][a-z\\']*=', f.read())\n",
    "\n",
    "        idk = [re.findall(u'[a-z\\']+', s) for s in idk]\n",
    "        idk = [x for y in idk for x in y]\n",
    "    with open('most_helpful.txt', 'wb') as f:\n",
    "        pickle.dump(idk, f)\n",
    "    return idk\n",
    "\n",
    "\n",
    "\n",
    "[1, 2, 3, 4]\n",
    "def check_acc(pred, Ytest):\n",
    "    thing = list(zip(pred, Ytest))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for (p,r) in thing:\n",
    "        if p == r:\n",
    "            correct += 1\n",
    "    #         print(\"correct\", p,r)\n",
    "        else:\n",
    "    #         print(\"incorrect\", p,r)\n",
    "            total += 1\n",
    "    #     print(p,r)\n",
    "    print(correct, total)\n",
    "    # pprint(thing)\n",
    "\n",
    "if debug > 1:\n",
    "    print(Ytrain.count('pos'),Ytrain.count('neg'), len(Ytrain))\n",
    "    print(Ytest.count('pos'),Ytest.count('neg'), len(Ytest))\n",
    "\n",
    "    print(Ytrain[:150])\n",
    "     #pprint(list(zip(Ytrain[250:255],train[250:255])))\n",
    "\n",
    "def run_model(train_zip, test_zip):\n",
    "    encoding = maxent.TypedMaxentFeatureEncoding.train(train_zip)\n",
    "\n",
    "    v = .01\n",
    "    model = maxent.MaxentClassifier.train(train_zip, encoding=encoding, trace=4, min_lldelta=v)\n",
    "    print(nltk.classify.accuracy(model, test_zip))\n",
    "    # pred = model.classify_many(y_feat_list)\n",
    "    pred = []\n",
    "    return model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, Ytrain, train_ID, test, Ytest, test_ID = revs_labels(train_xml, test_xml)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_features = 55\n",
    "num_bigrams = 90\n",
    "num_trigrams = 8\n",
    "all_words, all_bigrams, all_trigrams, feat_words, feat_bigrams, feat_trigrams = get_vocab(train, num_features, num_bigrams, num_trigrams)\n",
    "# all_words, all_bigrams, feat_words, feat_bigrams = get_vocab(train, num_features, num_bigrams)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feat_list = features(train, feat_words, feat_bigrams, feat_trigrams)\n",
    "y_feat_list = features(test, feat_words, feat_bigrams, feat_trigrams)\n",
    "test_zip = list(zip (y_feat_list, Ytest))\n",
    "train_zip = list(zip (x_feat_list, Ytrain))\n",
    "\n",
    "# model, pred = run_model(train_zip, test_zip)\n",
    "#     return model\n",
    "# x_feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.show_most_informative_features(300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     50
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# model1 = first_pass(train_xml, test_xml, 200)\n",
    "# with open(\"model\" + str(round(random.random(),4)) + \".txt\", \"wb\") as fp:\n",
    "#     pickle.dump(model1, fp)\n",
    "# best_feats = find_best_feats(model1, 400)\n",
    "\n",
    "# model2 = second_pass(train_xml, test_xml, best_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594837937:a_good_man's_long_journey:wantz_upon_a_time_reviews_\"www.wantzuponatime.com\"\tpos\n",
      "0071463097:i_can't_really_rate_this_item...:catalina_sanchez_\"tatatiu\"\tneg\n",
      "0671027034:outstanding:brandon_michael\tpos\n",
      "0743200926:big_book_of_grilling,_bbq_and_rotisserie_cookbook:tweety_\"tweety\"\tneg\n",
      "0394536487:the_egotistical_master:\tneg\n",
      "061318114X:not_innate,_but_geographical_differences:luc_reynaert\tpos\n",
      "0962855057:yuck!!!!_just_a_bad_book!:bookeee\tneg\n",
      "0743254562:5.0_stars:jason_frost_\"rubicon\"\tpos\n",
      "1416509690:unbelievable:shirlee_lerner\tneg\n",
      "0061234001:freakonomics:ronald_l._rushton\tpos\n",
      "0670032506:ironic_--_an_unproductive_book_on_productivity:rundhc\tneg\n",
      "0826415717:an_opinion_on_hendrix_-_far_from_anything_new:t._walker\tneg\n",
      "0195045785:statecraft:christian_schlect\tpos\n",
      "0415921139:abstractionist_in_disguise:terrance_shock\tneg\n",
      "0316010294:made_my_son_a_reader!!:m._connelly_\"bookie\"\tpos\n",
      "1583483985:i_thought_i'd_come_away_with_useful_information...:m._ollila\tneg\n",
      "0316082597:will_there_be_pi_in_the_sky_by_and_by_when_you_die?:bruce_kodish\tpos\n",
      "0156013053:a_world_of_boring.__a_raging_sea_of_boring!:librum_\"6nomad9\"\tneg\n",
      "0156013053:could_have_been_better:m._griffin_\"viviankosiba\"\tneg\n",
      "0385319258:a_life-changing_read_for_humans_8_to_108:bradley_spencer_\"www.bradleyspencer.com\"\tpos\n",
      "0736651047:no_flavor,_no_color,_no_good:andees\tneg\n",
      "044020562X:awesome_read:john_d._hernandez_jr._\"jdhtampa\"\tpos\n",
      "0439653665:this_book_should_be_called_occanumba,_not_heartland!:chloe_symes_\"clo\"\tneg\n",
      "0439650828:sports!:\tpos\n",
      "0786804165:not_for_4_year_olds:sarah_levinson_slosberg\tneg\n",
      "0672326701:great_if_you_have_that_specific_model_blackberry:h._edwin_detlie_\"ed_detlie\"\tneg\n",
      "0060936770:you_can't_go_wrong_with_larry_gonick:m._shaffer\tpos\n",
      "0897500598:ye_gods_and_little_children:todd_ellner_\"biblioholic,_not_in_recovery\"\tneg\n",
      "0521297060:academic_classic:\tpos\n",
      "1594860246:for_hardcore_fans_only:jacob_m._lampert\tneg\n",
      "0744008263:a_soap-bubble_book:andrey_lenskiy\tneg\n",
      "0613863844:reinforces_things_you_tell_your_kids:j._robinson\tpos\n",
      "B0006F54TQ:not_very_satisfying_at_all.:missy_w._\"gatorgirl\"\tneg\n",
      "0517205742:read_it_as_a_child_and_now_use_it_as_a_professor:poppiti\tpos\n",
      "0881925845:lots_of_not_what_not_to_do.:\tneg\n",
      "0825424003:one_of_the_best_intro_books_on_the_subject!:matthew_rushing_\"starwars_fan\"\tpos\n",
      "1593555962:missed_the_bullseye_:-(:b._bentley_\"readhotcook'\"\tneg\n",
      "B000FZDKQG:in_a_word,_ego:qwester_\"queen\"\tneg\n",
      "1558608745:the_best_book_for_arm's_firmware_programmers_so_far:lethalgambit\tpos\n",
      "1565123875:disappointment:wbjonesjr1\tneg\n",
      "0671746219:dr._deming's_management_principles-_a_charming_illustration:\tpos\n",
      "0807206822:junie's_rude_and_i_can't_find_anyting_that_redeems_her._:j._breederland_\"cal_gal\"\tneg\n",
      "0613921089:useful_insights_from_dell's_direct_sales_success_story:rolf_dobelli\tpos\n",
      "1857444027:poorly_organized:michael_d._archer\tneg\n",
      "1886513686:reviews_by_s._douglas_scotty_and_hardluck_stink:james_\"james\"\tneg\n",
      "0800758943:tender,_touching_and_humorous!:\tpos\n",
      "0596008775:badly_out_of_date:c._copp\tneg\n",
      "080411952X:wonderful,_dramatic,_suspensful,_touching,_and_many_other_things_all_rolled_into_one.:s._k._simmons\tpos\n",
      "0345441060:snake_oil:greg_sever_\"erth2sever\"\tneg\n",
      "0345467930:jules_gets_four_stars:avid_reader_\"avid_reader\"\tpos\n",
      "0684187787:know_your_woods?_not_after_reading_this_book:alan_carroll\tneg\n",
      "0465041914:what_a_dirty_trick:\tneg\n",
      "0756605954:excellent_beginners_book:n._champeny\tpos\n",
      "0156000776:no_way:\tneg\n",
      "0143035584:incredibly_useful!:josh\tpos\n",
      "0425181448:a_backlash_wolf_in_sheeps_clothing:l._saxon\tneg\n",
      "0671575236:deep_waters:k._hill_\"lashone\"\tpos\n",
      "0571226027:yawn:filth_reload_\"fort_delilah\"\tneg\n",
      "0671693808:look_at_it_from_the_child's_point_of_view...:mjm\tneg\n",
      "0596002815:learning_python:ron_mccafferty\tpos\n",
      "1580082335:why_are_reviews_same_for_revised_edition:bookloverfla\tneg\n",
      "0944435297:\"excellent_source_of_frozen_yogurt_recipes\":dave_brown_\"(one_of_thousands_of_dave_browns...)\"\tpos\n",
      "0767911733:misinformation_and_euro-centric:g._feng_\"gary\"\tneg\n",
      "0451140001:i_kept_waiting_for_her_to_leave_him:pat_\"readaholic\"\tneg\n",
      "0465006175:a_very_responsible_and_important_study:shalom_freedman_\"shalom_freedman\"\tpos\n",
      "0842369945:\"strong-willed_child\"?:james_c._talbot_\"kidman\"\tneg\n",
      "0300108834:historical_primer:randy_cook\tpos\n",
      "0060188782:my_brother's_experience_with_the_perricone_prescription:c._henning\tneg\n",
      "1556523998:the_greatest_book_on_john_lennon:richard_culter\tpos\n",
      "1411627679:boring....don't_bother_with_it.:a_reader\tneg\n",
      "0898747929:sounds_like_the_author_reviewed_this_himself:long_b._hoang\tneg\n",
      "0072262397:great_detailed_tutorial_for_those_new_to_reporting_services:yannick_salgleda_\"yannick\"\tpos\n",
      "0964135876:a_bad_way_to_spend_bucks:nahuel_ricardo_garavaglia\tneg\n",
      "0613538811:all_the_world's_children_have_the_same_wants_and_needs:a_reader\tpos\n",
      "0743492560:poorly_researched,_and_not_accurate_for_many_drugs:mary\tneg\n",
      "0399528105:kelly_ripa_loved_it!:\"ftknyc\"\tpos\n",
      "0842305076:violence_begets_violence:jo_york\tneg\n",
      "0782142605:somewhat_disappointed...:robin_cobin\tneg\n",
      "0440578299:a_must_for_any_lover_of_baseball:jimmy_hayde_(haydej@ntr.net)\tpos\n",
      "0674301188:an_effort_too_far_in_repetitious_jargon:mrs._g._pollock_\"balding_red-faced_sprog\"\tneg\n",
      "1580178421:small_sizes:d._g._van_velsen_\"-_eddie\"\tpos\n",
      "0151005346:a_world_of_boring.__a_raging_sea_of_boring!:librum_\"6nomad9\"\tneg\n",
      "0708925723:class_differences:mary_e._sibley\tpos\n",
      "1565844157:history_by_conjecture:\"jrolfe\"\tneg\n",
      "1933110171:in_way_over_her_head:alexandra_wolfe_\"the_wry_writer\"\tneg\n",
      "1400081629:an_inspiration_and_a_joy:jeff_wignall_\"author,_the_joy_of_digital_photography\"\tpos\n",
      "0399129030:you'd_think_the_book_would_be_about_natalie...:caitlin_m._guhl\tneg\n",
      "0613310829:my_son_chose_his_school_here:momoftwosons\tpos\n",
      "0696212226:repackaged_prepared_foods:michelle_kinslow\tneg\n",
      "0805029036:a_valuable_tool:bookseller\tpos\n",
      "0740761811:diy_cover_up:julia_lupton_\"design-your-life.org\"\tneg\n",
      "0786713992:i_make_movies_and_travel_extensively._my_life_is_great._:aco\tneg\n",
      "0525469516:amazing:emma\tpos\n",
      "0596101732:miserable_dictionary_of_doublespeak:m.i.b.\tneg\n",
      "0393316041:think_while_laughing_!:n._gangahar\tpos\n",
      "0385514573:boring:o._gonzalez\tneg\n",
      "097160200X:lacking:m._roman_\"matt1234567\"\tneg\n",
      "1891389319:finally,_no_more_\"lousy_and_ridiculous\"_for_chemistry_graduate_students:itschmical\tpos\n",
      "0312273193:it's_just_\"reefer_madness\"_:r._johns\tneg\n",
      "1417725184:tremendous:fred_franklin\tpos\n"
     ]
    }
   ],
   "source": [
    "pred = Ytest\n",
    "for ID,pred in list(zip(test_ID, pred)):\n",
    "        print(\"%s\\t%s\"% (ID.strip(), pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
